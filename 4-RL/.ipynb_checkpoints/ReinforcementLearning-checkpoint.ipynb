{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will learn how to create a reinforcmenet learning agent for self driving Mario Kart.\n",
    "Then, we will build a leaderboard to compare the algrithms we build.\n",
    "\n",
    "## Goals\n",
    "\n",
    "The main goals of implementing self driving Mario Kart are:\n",
    "- Understand the basics of Reinforcement Learning\n",
    "- Get familiar with Open AI Gym and Universe\n",
    "- Create an agent that is capable of learning by itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reinforcement Learning\n",
    "\n",
    "## 1.1. Introduction\n",
    "Those interested in the world of machine learning are aware of the capabilities of reinforcement-learning-based AI. The past few years have seen many breakthroughs using reinforcement learning (RL). The company DeepMind combined deep learning with reinforcement learning to achieve above-human results on a multitude of Atari games and, in March 2016, defeated Go champion Le Sedol four games to one. Though RL is currently excelling in many game environments, it is a novel way to solve problems that require optimal decisions and efficiency, and will surely play a part in machine intelligence to come.\n",
    "\n",
    "Reinforcement learning, explained simply, is a computational approach where an agent interacts with an environment by taking actions in which it tries to maximize an accumulated reward. \n",
    "Here is a simple graph (the agent-environement loop), from the book [Reinforcement Learning: An Introduction 2nd Edition](http://incompleteideas.net/sutton/book/the-book-2nd.html) :\n",
    "\n",
    "![RL](https://d3ansictanv2wj.cloudfront.net/image3-5f8cbb1fb6fb9132fef76b13b8687bfc.png)\n",
    "\n",
    "An agent in a current state (St) takes an action (At) to which the environment reacts and responds, returning a new state(St+1) and reward (Rt+1) to the agent. Given the updated state and reward, the agent chooses the next action, and the loop repeats until an environment is solved or terminated.\n",
    "\n",
    "Reinforcement learning provides the capacity for us not only to teach an artificial agent how to act, but to allow it to learn through it’s own interactions with an environment. By combining the complex representations that deep neural networks can learn with the goal-driven learning of an RL agent, computers have accomplished some amazing feats, like [beating humans at over a dozen Atari games](https://deepmind.com/dqn), and [defeating the Go world champion](https://deepmind.com/alpha-go).\n",
    "\n",
    "Learning how to build these agents requires a bit of a change in thinking for anyone used to working in a supervised learning setting though. Gone is the ability to simply get the algorithm to pair certain stimuli with certain responses. Instead RL algorithms must enable the agent to learn the correct pairings itself through the use of observations, rewards, and actions. Since there is no longer a “True” correct action for an agent to take in any given circumstance that we can just tell it, things get a little tricky. In this post and those to follow, I will be walking through the creation and training of reinforcement learning agents. The agent and task will begin simple, so that the concepts are clear, and then work up to more complex task and environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. OpenAI\n",
    "\n",
    "OpenAI was founded in late 2015 as a non-profit with a mission to “build safe artificial general intelligence (AGI) and ensure AGI's benefits are as widely and evenly distributed as possible.” In addition to exploring many issues regarding AGI, one major contribution that OpenAI made to the machine learning world was developing both the Gym and Universe software platforms.\n",
    "\n",
    "### OpenAI Gym\n",
    "OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms. It makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. You can use it from Python code, and soon from other languages.\n",
    "\n",
    "OpenAI Gym consists of two parts:\n",
    "- The gym open-source library: a collection of test problems — environments — that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms.\n",
    "- The OpenAI Gym service: a site and API allowing people to meaningfully compare performance of their trained agents.\n",
    "\n",
    "### Running our first agent\n",
    "Here's a bare minimum example of getting something running. This will run an instance of the CartPole-v0 environment for 1000 timesteps, rendering the environment at each step. You should see a window pop up rendering the classic cart-pole problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:20:04,862] Making new env: CartPole-v0\n",
      "[2018-06-04 07:20:04,969] You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"./Videos/cartpole-no-reset.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"./Videos/cartpole-no-reset.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to see some other environments in action, try replacing CartPole-v0 above with something like MountainCar-v0, MsPacman-v0 (requires the Atari dependency), or Hopper-v1 (requires the MuJoCo dependencies). Environments all descend from the Env base class.\n",
    "\n",
    "Note that if you're missing any dependencies, you should get a helpful error message telling you what you're missing.  Installing a missing dependency is generally pretty simple. You'll also need a MuJoCo license for Hopper-v1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observtations\n",
    "\n",
    "If we ever want to do better than take random actions at each step, it'd probably be good to actually know what our actions are doing to the environment.\n",
    "\n",
    "The environment's step function returns exactly what we need. In fact, step returns four values. These are:\n",
    "\n",
    "- observation (object): an environment-specific object representing your observation of the environment. For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "- reward (float): amount of reward achieved by the previous action. The scale varies between environments, but the goal is always to increase your total reward.\n",
    "- done (boolean): whether it's time to reset the environment again. Most (but not all) tasks are divided up into well-defined episodes, and done being True indicates the episode has terminated. (For example, perhaps the pole tipped too far, or you lost your last life.)\n",
    "- info (dict): diagnostic information useful for debugging. It can sometimes be useful for learning (for example, it might contain the raw probabilities behind the environment's last state change). However, official evaluations of your agent are not allowed to use this for learning.\n",
    "\n",
    "This is just an implementation of the classic \"agent-environment loop\". Each timestep, the agent chooses an action, and the environment returns an observation and a reward.\n",
    "\n",
    "![agent-environment loop](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
    "\n",
    "The process gets started by calling reset, which returns an initial observation. So a more proper way of writing the previous code would be to respect the done flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Two-Armed Bandit\n",
    "\n",
    "The simplest reinforcement learning problem is the n-armed bandit. Essentially, there are n-many slot machines, each with a different fixed payout probability. The goal is to discover the machine with the best payout, and maximize the returned reward by always choosing it. We are going to make it even simpler, by only having two possible slot machines to choose between. In fact, this problem is so simple that it is more of a precursor to real RL problems than one itself. \n",
    "\n",
    "Actually, typical aspects of a task that make it an RL problem are the following:\n",
    "\n",
    "- Different actions yield different rewards. For example, when looking for treasure in a maze, going left may lead to the treasure, whereas going right may lead to a pit of snakes.\n",
    "- Rewards are delayed over time. This just means that even if going left in the above example is the right thing to do, we may not know it till later in the maze.\n",
    "- Reward for an action is conditional on the state of the environment. Continuing the maze example, going left may be ideal at a certain fork in the path, but not at others.\n",
    "\n",
    "The n-armed bandit is a nice starting place because we don’t have to worry about aspects #2 and 3. All we need to focus on is learning which rewards we get for each of the possible actions, and ensuring we chose the optimal ones. \n",
    "\n",
    "In the context of RL lingo, this is called learning a policy. We are going to be using a method called policy gradients, where our simple neural network learns a policy for picking actions by adjusting its weights through gradient descent using feedback from the environment. \n",
    "There is another approach to reinforcement learning where agents learn value functions. In those approaches, instead of learning the optimal action in a given state, the agent learns to predict how good a given state or action will be for the agent to be in. Both approaches allow agents to learn good behavior, but the policy gradient approach is a little more direct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Q-Learning and Exploration\n",
    "\n",
    "Unlike policy gradient methods, which attempt to learn functions which directly map an observation to an action, Q-Learning attempts to learn the value of being in a given state, and taking a specific action there. While both approaches ultimately allow us to take intelligent actions given a situation, the means of getting to that action differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we are going to be attempting to solve the [FrozenLake](https://gym.openai.com/envs/FrozenLake-v0) environment from the OpenAI gym. For those unfamiliar, the [OpenAI gym](https://gym.openai.com/) provides an easy way for people to experiment with their learning agents in an array of provided toy games. The FrozenLake environment consists of a 4x4 grid of blocks, each one either being the start block, the goal block, a safe frozen block, or a dangerous hole. The objective is to have an agent learn to navigate from the start to the goal without moving onto a hole. At any given time the agent can choose to move either up, down, left, or right. The catch is that there is a wind which occasionally blows the agent onto a space they didn’t choose. As such, perfect performance every time is impossible, but learning to avoid the holes and reach the goal are certainly still doable. The reward at every step is 0, except for entering the goal, which provides a reward of 1. Thus, we will need an algorithm that learns long-term expected rewards. This is exactly what Q-Learning is designed to provide.\n",
    "\n",
    "In it’s simplest implementation, Q-Learning is a table of values for every state (row) and action (column) possible in the environment. Within each cell of the table, we learn a value for how good it is to take a given action within a given state. In the case of the FrozenLake environment, we have 16 possible states (one for each block), and 4 possible actions (the four directions of movement), giving us a 16x4 table of Q-values. We start by initializing the table to be uniform (all zeros), and then as we observe the rewards we obtain for various actions, we update the table accordingly.\n",
    "\n",
    "We make updates to our Q-table using something called the [Bellman equation](https://en.wikipedia.org/wiki/Bellman_equation), which states that the expected long-term reward for a given action is equal to the immediate reward from the current action combined with the expected reward from the best future action taken at the following state. In this way, we reuse our own Q-table when estimating how to update our table for future actions! In equation form, the rule looks like this:\n",
    "\n",
    "                Eq 1. Q(s,a) = r + γ(max(Q(s’,a’))\n",
    "                \n",
    "                \n",
    "This says that the Q-value for a given state (s) and action (a) should represent the current reward (r) plus the maximum discounted (γ) future reward expected according to our own table for the next state (s’) we would end up in. The discount variable allows us to decide how important the possible future rewards are compared to the present reward. By updating in this way, the table slowly begins to obtain accurate measures of the expected future reward for a given action in a given state. Below is a Python walkthrough of the Q-Table algorithm implemented in the FrozenLake environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:21:27,642] Making new env: FrozenLake-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.629\n",
      "Final Q-Table Values\n",
      "[[2.10799263e-01 1.01009378e-02 1.55837837e-02 1.41652064e-02]\n",
      " [1.78600526e-04 1.60928702e-04 5.93509283e-04 2.02593865e-01]\n",
      " [3.13566865e-03 1.48131656e-03 4.15535596e-03 1.44455912e-01]\n",
      " [8.02038186e-04 8.93375800e-04 6.68525405e-04 5.87832404e-02]\n",
      " [3.31181379e-01 2.33374391e-03 2.87647794e-03 2.71939045e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.09361623e-04 4.24355147e-03 1.68818058e-04 1.23796036e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.66111499e-03 1.82671705e-03 1.25873802e-03 2.32768410e-01]\n",
      " [0.00000000e+00 6.38280551e-01 3.35062847e-03 2.34232079e-03]\n",
      " [9.04579528e-01 7.95613892e-04 2.41367424e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.97112872e-01 0.00000000e+00]\n",
      " [0.00000000e+00 9.88841402e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the environement\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# Implement Q-Table Learning Algorithm\n",
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# Set learning parameters\n",
    "lr = .8\n",
    "y = .95\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "#jList = []\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        #Get new state and reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)\n",
    "\n",
    "print \"Score over time: \" +  str(sum(rList)/num_episodes)\n",
    "print \"Final Q-Table Values\"\n",
    "print Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Q-Learning with Neural Networks\n",
    "\n",
    "Now, you may be thinking: tables are great, but they don’t really scale, do they? While it is easy to have a 16x4 table for a simple grid world, the number of possible states in any modern game or real-world environment is nearly infinitely larger. For most interesting problems, tables simply don’t work. We instead need some way to take a description of our state, and produce Q-values for actions without a table: that is where neural networks come in. By acting as a function approximator, we can take any number of possible states that can be represented as a vector and learn to map them to Q-values.\n",
    "\n",
    "\n",
    "In the case of the FrozenLake example, we will be using a one-layer network which takes the state encoded in a one-hot vector (1x16), and produces a vector of 4 Q-values, one for each action. Such a simple network acts kind of like a glorified table, with the network weights serving as the old cells. The key difference is that we can easily expand the Tensorflow network with added layers, activation functions, and different input types, whereas all that is impossible with a regular table. The method of updating is a little different as well. Instead of directly updating our table, with a network we will be using backpropagation and a loss function. Our loss function will be sum-of-squares loss, where the difference between the current predicted Q-values, and the “target” value is computed and the gradients passed through the network. In this case, our Q-target for the chosen action is the equivalent to the Q-value computed in equation 1 above.\n",
    "\n",
    "            Eq2. Loss = ∑(Q-target - Q)²\n",
    "            \n",
    "Below is the Tensorflow walkthrough of implementing our simple Q-Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:22:49,922] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the environement\n",
    "env = gym.make('FrozenLake-v0')\n",
    "\n",
    "# The Q-Network Approach\n",
    "# Implementing the network itself\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([16,4],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "nextQ = tf.placeholder(shape=[1,4],dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:23:02,653] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of succesful episodes: 0.337%\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "num_episodes = 2000\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 99:\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:np.identity(16)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "            #Get new state and reward from environment\n",
    "            s1,r,d,_ = env.step(a[0])\n",
    "            #Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:np.identity(16)[s1:s1+1]})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            #Train our network using target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:np.identity(16)[s:s+1],nextQ:targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            if d == True:\n",
    "                #Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "print \"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics on network performance\n",
    "We can see that the network beings to consistly reach the goal around the 750 episode mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9d1c5be590>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also begins to progress through the environment for longer than chance aroudn the 750 mark as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9d1c4e8bd0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the network learns to solve the FrozenLake problem, it turns out it doesn’t do so quite as efficiently as the Q-Table. While neural networks allow for greater flexibility, they do so at the cost of stability when it comes to Q-Learning. There are a number of possible extensions to our simple Q-Network which allow for greater performance and more robust learning. Two tricks in particular are referred to as Experience Replay and Freezing Target Networks. Those improvements and other tweaks were the key to getting Atari-playing Deep Q-Networks, and we will be exploring those additions in the future. For more info on the theory behind Q-Learning, see this great post by Tambet Matiisen. I hope this tutorial has been helpful for those curious about how to implement simple Q-Learning algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Policy Gradient\n",
    "\n",
    "The simplest way to think of a Policy gradient network is one which produces explicit outputs. In the case of our bandit, we don’t need to condition these outputs on any state. As such, our network will consist of just a set of weights, with each corresponding to each of the possible arms to pull in the bandit, and will represent how good our agent thinks it is to pull each arm. If we initialize these weights to 1, then our agent will be somewhat optimistic about each arm’s potential reward.\n",
    "\n",
    "To update our network, we will simply try an arm with an e-greedy policy (See Part 7 for more on action-selection strategies). This means that most of the time our agent will choose the action that corresponds to the largest expected value, but occasionally, with e probability, it will choose randomly. In this way, the agent can try out each of the different arms to continue to learn more about them. Once our agent has taken an action, it then receives a reward of either 1 or -1. With this reward, we can then make an update to our network using the policy loss equation:\n",
    "\n",
    "                Loss = -log(π)*A\n",
    "\n",
    "A is advantage, and is an essential aspect of all reinforcement learning algorithms. Intuitively it corresponds to how much better an action was than some baseline. In future algorithms, we will develop more complex baselines to compare our rewards to, but for now we will assume that the baseline is 0, and it can be thought of as simply the reward we received for each action.\n",
    "\n",
    "π is the policy. In this case, it corresponds to the chosen action’s weight.\n",
    "\n",
    "Intuitively, this loss function allows us to increase the weight for actions that yielded a positive reward, and decrease them for actions that yielded a negative reward. In this way the agent will be more or less likely to pick that action in the future. By taking actions, getting rewards, and updating our network in this circular manner, we will quickly converge to an agent that can solve our bandit problem! Don’t take my word for it though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: The Multi-armed bandit\n",
    "\n",
    "This tutorial contains a simple example of how to build a policy-gradient based agent that can solve the multi-armed bandit problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bandits\n",
    "\n",
    "Here we define our bandits. For this example we are using a four-armed bandit. The pullBandit function generates a random number from a normal distribution with a mean of 0. The lower the bandit number, the more likely a positive reward will be returned. We want our agent to learn to always choose the bandit that will give that positive reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List out our bandits. Currently bandit 4 (index#3) is set to most often provide a positive reward.\n",
    "bandits = [0.2,0,-0.2,-5]\n",
    "num_bandits = len(bandits)\n",
    "def pullBandit(bandit):\n",
    "    #Get a random number.\n",
    "    result = np.random.randn(1)\n",
    "    if result > bandit:\n",
    "        #return a positive reward.\n",
    "        return 1\n",
    "    else:\n",
    "        #return a negative reward.\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent\n",
    "The code below established our simple neural agent. It consists of a set of values for each of the bandits. Each value is an estimate of the value of the return from choosing the bandit. We use a policy gradient method to update the agent by moving the value for the selected action toward the recieved reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#These two lines established the feed-forward part of the network. This does the actual choosing.\n",
    "weights = tf.Variable(tf.ones([num_bandits]))\n",
    "chosen_action = tf.argmax(weights,0)\n",
    "\n",
    "#The next six lines establish the training proceedure. We feed the reward and chosen action into the network\n",
    "#to compute the loss, and use it to update the network.\n",
    "reward_holder = tf.placeholder(shape=[1],dtype=tf.float32)\n",
    "action_holder = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "responsible_weight = tf.slice(weights,action_holder,[1])\n",
    "loss = -(tf.log(responsible_weight)*reward_holder)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "update = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Agent\n",
    "We will train our agent by taking actions in our environment, and recieving rewards. Using the rewards and actions, we can know how to properly update our network in order to more often choose actions that will yield the highest rewards over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward for the 4 bandits: [-1.  0.  0.  0.]\n",
      "Running reward for the 4 bandits: [ 0. -1.  0. 46.]\n",
      "Running reward for the 4 bandits: [ 0.  2.  0. 93.]\n",
      "Running reward for the 4 bandits: [ -1.   2.   1. 139.]\n",
      "Running reward for the 4 bandits: [ -2.   3.  -1. 183.]\n",
      "Running reward for the 4 bandits: [ -3.   4.   1. 227.]\n",
      "Running reward for the 4 bandits: [ -2.   4.   2. 275.]\n",
      "Running reward for the 4 bandits: [ -1.   4.   2. 320.]\n",
      "Running reward for the 4 bandits: [ -1.   4.   2. 370.]\n",
      "Running reward for the 4 bandits: [ -2.   4.   5. 414.]\n",
      "Running reward for the 4 bandits: [ -1.   4.   6. 462.]\n",
      "Running reward for the 4 bandits: [ -2.   4.   6. 509.]\n",
      "Running reward for the 4 bandits: [ -3.   5.   7. 554.]\n",
      "Running reward for the 4 bandits: [ -3.   6.   7. 603.]\n",
      "Running reward for the 4 bandits: [ -3.   7.   7. 650.]\n",
      "Running reward for the 4 bandits: [ -4.   7.   7. 697.]\n",
      "Running reward for the 4 bandits: [ -4.   6.   5. 744.]\n",
      "Running reward for the 4 bandits: [ -4.   7.   6. 790.]\n",
      "Running reward for the 4 bandits: [ -4.   6.   7. 836.]\n",
      "Running reward for the 4 bandits: [ -5.   5.   8. 881.]\n",
      "The agent thinks bandit 4 is the most promising....\n",
      "...and it was right!\n"
     ]
    }
   ],
   "source": [
    "total_episodes = 1000 #Set total number of episodes to train agent on.\n",
    "total_reward = np.zeros(num_bandits) #Set scoreboard for bandits to 0.\n",
    "e = 0.1 #Set the chance of taking a random action.\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    while i < total_episodes:\n",
    "        \n",
    "        #Choose either a random action or one from our network.\n",
    "        if np.random.rand(1) < e:\n",
    "            action = np.random.randint(num_bandits)\n",
    "        else:\n",
    "            action = sess.run(chosen_action)\n",
    "        \n",
    "        reward = pullBandit(bandits[action]) #Get our reward from picking one of the bandits.\n",
    "        \n",
    "        #Update the network.\n",
    "        _,resp,ww = sess.run([update,responsible_weight,weights], feed_dict={reward_holder:[reward],action_holder:[action]})\n",
    "        \n",
    "        #Update our running tally of scores.\n",
    "        total_reward[action] += reward\n",
    "        if i % 50 == 0:\n",
    "            print \"Running reward for the \" + str(num_bandits) + \" bandits: \" + str(total_reward)\n",
    "        i+=1\n",
    "print \"The agent thinks bandit \" + str(np.argmax(ww)+1) + \" is the most promising....\"\n",
    "if np.argmax(ww) == np.argmax(-np.array(bandits)):\n",
    "    print \"...and it was right!\"\n",
    "else:\n",
    "    print \"...and it was wrong!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Policy-based Agents\n",
    "\n",
    "Environments which pose the full problem to an agent are referred to as Markov Decision Processes (MDPs). These environments not only provide rewards and state transitions given actions, but those rewards are also condition on the state of the environment and the action the agent takes within that state. These dynamics are also temporal, and can be delayed over time.\n",
    "\n",
    "To be a little more formal, we can define a Markov Decision Process as follows. An MDP consists of a set of all possible states S from which our agent at any time will experience s. A set of all possible actions A from which our agent at any time will take action a. Given a state action pair (s, a), the transition probability to a new state s’ is defined by T(s, a), and the reward r is given by R(s, a). As such, at any time in an MDP, an agent is given a state s, takes action a, and receives new state s’ and reward r.\n",
    "\n",
    "While it may seem relatively simple, we can pose almost any task we could think of as an MDP. For example, imagine opening a door. The state is the vision of the door that we have, as well as the position of our body and door in the world. The actions are our every movement our body could make. The reward in this case is the door successfully opening. Certain actions, like walking toward the door are essential to solving the problem, but aren’t themselves reward-giving, since only actually opening the door will provide the reward. In this way, an agent needs to learn to assign value to actions the lead eventually to the reward, hence the introduction of temporal dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Cart-Pole Task\n",
    "\n",
    "In order to accomplish this, we are going to need a challenge that is more difficult for the agent than the two-armed bandit. To meet provide this challenge we are going to utilize the OpenAI gym, a collection of reinforcement learning environments. We will be using one of the classic tasks, the Cart-Pole. To learn more about the OpenAI gym, and this specific task, check out their tutorial [here](https://gym.openai.com/docs). Essentially, we are going to have our agent learn how to balance a pole for as long as possible without it falling. Unlike the two-armed bandit, this task requires:\n",
    "\n",
    "- Observations — The agent needs to know where pole currently is, and the angle at which it is balancing. To accomplish this, our neural network will take an observation and use it when producing the probability of an action.\n",
    "\n",
    "- Delayed reward — Keeping the pole in the air as long as possible means moving in ways that will be advantageous for both the present and the future. To accomplish this we will adjust the reward value for each observation-action pair using a function that weighs actions over time.\n",
    "\n",
    "To take reward over time into account, the form of Policy Gradient we used in the previous tutorials will need a few adjustments. The first of which is that we now need to update our agent with more than one experience at a time. To accomplish this, we will collect experiences in a buffer, and then occasionally use them to update the agent all at once. These sequences of experience are sometimes referred to as rollouts, or experience traces. We can’t just apply these rollouts by themselves however, we will need to ensure that the rewards are properly adjusted by a discount factor\n",
    "\n",
    "Intuitively this allows each action to be a little bit responsible for not only the immediate reward, but all the rewards that followed. We now use this modified reward as an estimation of the advantage in our loss equation. With those changes, we are ready to solve CartPole!\n",
    "\n",
    "And with that we have a fully-functional reinforcement learning agent. Our agent is still far from the state of the art though. While we are using a neural network for the policy, the network still isn’t as deep or complex as the most advanced networks. In the next post I will be showing how to use Deep Neural Networks to create agents able to learn more complex relationships with the environment in order to play a more exciting game than pole balancing. In doing so, I will be diving into the kinds of representations that a network learns for more complex environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Model-Based RL\n",
    "\n",
    "Now we will introduce the concept of a model of the environment that the agent can use to improve it’s performance.\n",
    "\n",
    "What is a model and why would we want to use one? In this case, a model is going to be a neural network that attempts to learn the dynamics of the real environment. For example, in the CartPole we would like a model to be able to predict the next position of the Cart given the previous position and an action. By learning an accurate model, we can train our agent using the model rather than requiring to use the real environment every time. While this may seem less useful when the real environment is itself a simulation, like in our CartPole task, it can have huge advantages when attempting to learn policies for acting in the physical world.\n",
    "\n",
    "Unlike in computer simulations, physical environments take time to navigate, and the physical rules of the world prevent things like easy environment resets from being feasible. Instead, we can save time and energy by building a model of the environment. With such a model, an agent can ‘imagine’ what it might be like to move around the real environment, and we can train a policy on this imagined environment in addition to the real one. If we were given a good enough model of an environment, an agent could be trained entirely on that model, and even perform well when placed into a real environment for the first time.\n",
    "\n",
    "How are we going to accomplish this in Tensorflow? As I mentioned above, we are going to be using a neural network that will learn the transition dynamics between a previous observation and action, and the expected new observation, reward, and done state. Our training procedure will involve switching between training our model using the real environment, and training our agent’s policy using the model environment. By using this approach we will be able to learn a policy that allows our agent to solve the CartPole task without actually ever training the policy on the real environment! Read the iPython notebook below for the details on how this is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this following part we implement a policy and model network which work in tandem to solve the CartPole reinforcement learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries and starting CartPole environment\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# from modelAny import *\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import rnn\n",
    "# from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:29:23,679] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "H = 8 # number of hidden layer neurons\n",
    "learning_rate = 1e-2\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = False # resume from previous checkpoint?\n",
    "\n",
    "model_bs = 3 # Batch size when learning from model\n",
    "real_bs = 3 # Batch size when learning from real environment\n",
    "\n",
    "# model initialization\n",
    "D = 4 # input dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-04 07:29:30,491] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "observations = tf.placeholder(tf.float32, [None,4] , name=\"input_x\")\n",
    "W1 = tf.get_variable(\"W1\", shape=[4, H],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1 = tf.nn.relu(tf.matmul(observations,W1))\n",
    "W2 = tf.get_variable(\"W2\", shape=[H, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "score = tf.matmul(layer1,W2)\n",
    "probability = tf.nn.sigmoid(score)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name=\"input_y\")\n",
    "advantages = tf.placeholder(tf.float32,name=\"reward_signal\")\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "W1Grad = tf.placeholder(tf.float32,name=\"batch_grad1\")\n",
    "W2Grad = tf.placeholder(tf.float32,name=\"batch_grad2\")\n",
    "batchGrad = [W1Grad,W2Grad]\n",
    "loglik = tf.log(input_y*(input_y - probability) + (1 - input_y)*(input_y + probability))\n",
    "loss = -tf.reduce_mean(loglik * advantages) \n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "updateGrads = adam.apply_gradients(zip(batchGrad,tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Network\n",
    "Here we implement a multi-layer neural network that predicts the next observation, reward, and done state from a current state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mH = 256 # model layer size\n",
    "\n",
    "input_data = tf.placeholder(tf.float32, [None, 5])\n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [mH, 50])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [50])\n",
    "\n",
    "previous_state = tf.placeholder(tf.float32, [None,5] , name=\"previous_state\")\n",
    "W1M = tf.get_variable(\"W1M\", shape=[5, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B1M = tf.Variable(tf.zeros([mH]),name=\"B1M\")\n",
    "layer1M = tf.nn.relu(tf.matmul(previous_state,W1M) + B1M)\n",
    "W2M = tf.get_variable(\"W2M\", shape=[mH, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B2M = tf.Variable(tf.zeros([mH]),name=\"B2M\")\n",
    "layer2M = tf.nn.relu(tf.matmul(layer1M,W2M) + B2M)\n",
    "wO = tf.get_variable(\"wO\", shape=[mH, 4],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wR = tf.get_variable(\"wR\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wD = tf.get_variable(\"wD\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "bO = tf.Variable(tf.zeros([4]),name=\"bO\")\n",
    "bR = tf.Variable(tf.zeros([1]),name=\"bR\")\n",
    "bD = tf.Variable(tf.ones([1]),name=\"bD\")\n",
    "\n",
    "\n",
    "predicted_observation = tf.matmul(layer2M,wO,name=\"predicted_observation\") + bO\n",
    "predicted_reward = tf.matmul(layer2M,wR,name=\"predicted_reward\") + bR\n",
    "predicted_done = tf.sigmoid(tf.matmul(layer2M,wD,name=\"predicted_done\") + bD)\n",
    "\n",
    "true_observation = tf.placeholder(tf.float32,[None,4],name=\"true_observation\")\n",
    "true_reward = tf.placeholder(tf.float32,[None,1],name=\"true_reward\")\n",
    "true_done = tf.placeholder(tf.float32,[None,1],name=\"true_done\")\n",
    "\n",
    "predicted_state = tf.concat([predicted_observation,predicted_reward,predicted_done],1)\n",
    "\n",
    "observation_loss = tf.square(true_observation - predicted_observation)\n",
    "\n",
    "reward_loss = tf.square(true_reward - predicted_reward)\n",
    "\n",
    "done_loss = tf.multiply(predicted_done, true_done) + tf.multiply(1-predicted_done, 1-true_done)\n",
    "done_loss = -tf.log(done_loss)\n",
    "\n",
    "\n",
    "model_loss = tf.reduce_mean(observation_loss + done_loss + reward_loss)\n",
    "\n",
    "modelAdam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "updateModel = modelAdam.minimize(model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetGradBuffer(gradBuffer):\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    return gradBuffer\n",
    "        \n",
    "def discount_rewards(r):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(xrange(0, r.size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n",
    "\n",
    "\n",
    "# This function uses our model to produce a new state when given a previous state and action\n",
    "def stepModel(sess, xs, action):\n",
    "    toFeed = np.reshape(np.hstack([xs[-1][0],np.array(action)]),[1,5])\n",
    "    myPredict = sess.run([predicted_state],feed_dict={previous_state: toFeed})\n",
    "    reward = myPredict[0][:,4]\n",
    "    observation = myPredict[0][:,0:4]\n",
    "    observation[:,0] = np.clip(observation[:,0],-2.4,2.4)\n",
    "    observation[:,2] = np.clip(observation[:,2],-0.4,0.4)\n",
    "    doneP = np.clip(myPredict[0][:,5],0,1)\n",
    "    if doneP > 0.1 or len(xs)>= 300:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Policy and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs,drs,ys,ds = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 1\n",
    "real_episodes = 1\n",
    "init = tf.initialize_all_variables()\n",
    "batch_size = real_bs\n",
    "\n",
    "drawFromModel = False # When set to True, will use model for observations\n",
    "trainTheModel = True # Whether to train the model\n",
    "trainThePolicy = False # Whether to train the policy\n",
    "switch_point = 1\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    rendering = False\n",
    "    sess.run(init)\n",
    "    observation = env.reset()\n",
    "    x = observation\n",
    "    gradBuffer = sess.run(tvars)\n",
    "    gradBuffer = resetGradBuffer(gradBuffer)\n",
    "    \n",
    "    while episode_number <= 5000:\n",
    "        # Start displaying environment once performance is acceptably high.\n",
    "        if (reward_sum/batch_size > 150 and drawFromModel == False) or rendering == True : \n",
    "            env.render()\n",
    "            rendering = True\n",
    "            \n",
    "        x = np.reshape(observation,[1,4])\n",
    "\n",
    "        tfprob = sess.run(probability,feed_dict={observations: x})\n",
    "        action = 1 if np.random.uniform() < tfprob else 0\n",
    "\n",
    "        # record various intermediates (needed later for backprop)\n",
    "        xs.append(x) \n",
    "        y = 1 if action == 0 else 0 \n",
    "        ys.append(y)\n",
    "        \n",
    "        # step the  model or real environment and get new measurements\n",
    "        if drawFromModel == False:\n",
    "            observation, reward, done, info = env.step(action)\n",
    "        else:\n",
    "            observation, reward, done = stepModel(sess,xs,action)\n",
    "                \n",
    "        reward_sum += reward\n",
    "        \n",
    "        ds.append(done*1)\n",
    "        drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "        if done: \n",
    "            \n",
    "            if drawFromModel == False: \n",
    "                real_episodes += 1\n",
    "            episode_number += 1\n",
    "\n",
    "            # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "            epx = np.vstack(xs)\n",
    "            epy = np.vstack(ys)\n",
    "            epr = np.vstack(drs)\n",
    "            epd = np.vstack(ds)\n",
    "            xs,drs,ys,ds = [],[],[],[] # reset array memory\n",
    "            \n",
    "            if trainTheModel == True:\n",
    "                actions = np.array([np.abs(y-1) for y in epy][:-1])\n",
    "                state_prevs = epx[:-1,:]\n",
    "                state_prevs = np.hstack([state_prevs,actions])\n",
    "                state_nexts = epx[1:,:]\n",
    "                rewards = np.array(epr[1:,:])\n",
    "                dones = np.array(epd[1:,:])\n",
    "                state_nextsAll = np.hstack([state_nexts,rewards,dones])\n",
    "\n",
    "                feed_dict={previous_state: state_prevs, true_observation: state_nexts,true_done:dones,true_reward:rewards}\n",
    "                loss,pState,_ = sess.run([model_loss,predicted_state,updateModel],feed_dict)\n",
    "            if trainThePolicy == True:\n",
    "                discounted_epr = discount_rewards(epr).astype('float32')\n",
    "                discounted_epr -= np.mean(discounted_epr)\n",
    "                discounted_epr /= np.std(discounted_epr)\n",
    "                tGrad = sess.run(newGrads,feed_dict={observations: epx, input_y: epy, advantages: discounted_epr})\n",
    "                \n",
    "                # If gradients becom too large, end training process\n",
    "                if np.sum(tGrad[0] == tGrad[0]) == 0:\n",
    "                    break\n",
    "                for ix,grad in enumerate(tGrad):\n",
    "                    gradBuffer[ix] += grad\n",
    "                \n",
    "            if switch_point + batch_size == episode_number: \n",
    "                switch_point = episode_number\n",
    "                if trainThePolicy == True:\n",
    "                    sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W2Grad:gradBuffer[1]})\n",
    "                    gradBuffer = resetGradBuffer(gradBuffer)\n",
    "\n",
    "                running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "                if drawFromModel == False:\n",
    "                    print 'World Perf: Episode %f. Reward %f. action: %f. mean reward %f.' % (real_episodes,reward_sum/real_bs,action, running_reward/real_bs)\n",
    "                    if reward_sum/batch_size > 200:\n",
    "                        break\n",
    "                reward_sum = 0\n",
    "\n",
    "                # Once the model has been trained on 100 episodes, we start alternating between training the policy\n",
    "                # from the model and training the model from the real environment.\n",
    "                if episode_number > 100:\n",
    "                    drawFromModel = not drawFromModel\n",
    "                    trainTheModel = not trainTheModel\n",
    "                    trainThePolicy = not trainThePolicy\n",
    "            \n",
    "            if drawFromModel == True:\n",
    "                observation = np.random.uniform(-0.1,0.1,[4]) # Generate reasonable starting point\n",
    "                batch_size = model_bs\n",
    "            else:\n",
    "                observation = env.reset()\n",
    "                batch_size = real_bs\n",
    "                \n",
    "print real_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking model representation\n",
    "\n",
    "Here we can examine how well the model is able to approximate the true environment after training. The green line indicates the real environment, and the blue indicates model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    plt.plot(pState[:,i])\n",
    "    plt.subplot(6,2,2*i+1)\n",
    "    plt.plot(state_nextsAll[:,i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are now two network involved, there are plenty of hyper-parameters to adjust in order to improve performance or efficiency. I encourage you to play with them in order to discover better means of combining the the models. In Part 4 I will be exploring how to utilize convolutional networks to learn representations of more complex environments, such as Atari games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Deep Q-Networks\n",
    "\n",
    "In this tutorial we will be walking through the creation of a Deep Q-Network. It will be built upon the simple one layer Q-network we created in Part 0, so I would recommend reading that first if you are new to reinforcement learning. While our ordinary Q-network was able to barely perform as well as the Q-Table in a simple game environment, Deep Q-Networks are much more capable. In order to transform an ordinary Q-Network into a DQN we will be making the following improvements:\n",
    "\n",
    "- Going from a single-layer network to a multi-layer convolutional network.\n",
    "- Implementing Experience Replay, which will allow our network to train itself using stored memories from it’s experience.\n",
    "- Utilizing a second “target” network, which we will use to compute target Q-values during our updates.\n",
    "\n",
    "It was these three innovations that allowed the [Google DeepMind team to achieve superhuman performance on dozens of Atari games using their DQN agent](http://www.davidqiu.com:8888/research/nature14236.pdf). We will be walking through each individual improvement, and showing how to implement it. We won’t stop there though. The pace of Deep Learning research is extremely fast, and the DQN of 2014 is no longer the most advanced agent around anymore. I will discuss two simple additional improvements to the DQN architecture, Double DQN and Dueling DQN, that allow for improved performance, stability, and faster training time. In the end we will have a network that can tackle a number of challenging Atari games, and we will demonstrate how to train the DQN to learn a basic navigation task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting from Q-Network to Deep Q-Network\n",
    "![DeepMind](https://cdn-images-1.medium.com/max/800/1*T54Ngd-b_CKcP3N6hyXLVg.png)\n",
    "\n",
    "### Addition 1: Convolutional Layers\n",
    "Since our agent is going to be learning to play video games, it has to be able to make sense of the game’s screen output in a way that is at least similar to how humans or other intelligent animals are able to. Instead of considering each pixel independently, convolutional layers allow us to consider regions of an image, and maintain spatial relationships between the objects on the screen as we send information up to higher levels of the network. In this way, they act similarly to human receptive fields. Indeed there is a body of research showing that convolutional neural network learn representations that are [similar to those of the primate visual cortex](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003963). As such, they are ideal for the first few elements within our network.\n",
    "\n",
    "In Tensorflow, we can utilize the tf.contrib.layers.convolution2d function to easily create a convolutional layer. We write for function as follows:\n",
    "\n",
    "    convolution_layer = tf.contrib.layers.convolution2d(inputs,num_outputs,kernel_size,stride,padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here num_outs refers to how many filters we would like to apply to the previous layer. kernel_size refers to how large a window we would like to slide over the previous layer. Stride refers to how many pixels we want to skip as we slide the window across the layer. Finally, padding refers to whether we want our window to slide over just the bottom layer (“VALID”) or add padding around it (“SAME”) in order to ensure that the convolutional layer has the same dimensions as the previous layer. For more information, see the [Tensorflow documentation](https://www.tensorflow.org/versions/r0.10/api_docs/python/contrib.layers.html#convolution2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition 2: Experience Replay\n",
    "The second major addition to make DQNs work is Experience Replay. The basic idea is that by storing an agent’s experiences, and then randomly drawing batches of them to train the network, we can more robustly learn to perform well in the task. By keeping the experiences we draw random, we prevent the network from only learning about what it is immediately doing in the environment, and allow it to learn from a more varied array of past experiences. Each of these experiences are stored as a tuple of <state,action,reward,next state>. The Experience Replay buffer stores a fixed number of recent memories, and as new ones come in, old ones are removed. When the time comes to train, we simply draw a uniform batch of random memories from the buffer, and train our network with them. For our DQN, we will build a simple class that handles storing and retrieving memories.\n",
    "\n",
    "### Addition 3: Separate Target Network\n",
    "The third major addition to the DQN that makes it unique is the utilization of a second network during the training procedure. This second network is used to generate the target-Q values that will be used to compute the loss for every action during training. Why not use just use one network for both estimations? The issue is that at every step of training, the Q-network’s values shift, and if we are using a constantly shifting set of values to adjust our network values, then the value estimations can easily spiral out of control. The network can become destabilized by falling into feedback loops between the target and estimated Q-values. In order to mitigate that risk, the target network’s weights are fixed, and only periodically or slowly updated to the primary Q-networks values. In this way training can proceed in a more stable manner.\n",
    "\n",
    "Instead of updating the target network periodically and all at once, we will be updating it frequently, but slowly. This technique was introduced in another DeepMind paper earlier this year, where they found that it stabilized the training process.\n",
    "\n",
    "### Going Beyond DQN\n",
    "With the additions above, we have everything we need to replicate the DWN of 2014. But the world moves fast, and a number of improvements above and beyond the DQN architecture described by DeepMind, have allowed for even greater performance and stability. Before training your new DQN on your favorite ATARI game, I would suggest checking the newer additions out. I will provide a description and some code for two of them: Double DQN, and Dueling DQN. Both are simple to implement, and by combining both techniques, we can achieve better performance with faster training times.\n",
    "\n",
    "### Double DQN\n",
    "The main intuition behind Double DQN is that the regular DQN often overestimates the Q-values of the potential actions to take in a given state. While this would be fine if all actions were always overestimates equally, there was reason to believe this wasn’t the case. You can easily imagine that if certain suboptimal actions regularly were given higher Q-values than optimal actions, the agent would have a hard time ever learning the ideal policy. In order to correct for this, the authors of DDQN paper propose a simple trick: instead of taking the max over Q-values when computing the target-Q value for our training step, we use our primary network to chose an action, and our target network to generate the target Q-value for that action. By decoupling the action choice from the target Q-value generation, we are able to substantially reduce the overestimation, and train faster and more reliably. Below is the new DDQN equation for updating the target value.\n",
    "\n",
    "        Q-Target = r + γQ(s’,argmax(Q(s’,a,ϴ),ϴ’))\n",
    "        \n",
    "### Dueling DQN\n",
    "![Dueling DQN](https://cdn-images-1.medium.com/max/800/1*N_t9I7MeejAoWlDuH1i7cw.png)\n",
    "\n",
    "In order to explain the reasoning behind the architecture changes that Dueling DQN makes, we need to first explain some a few additional reinforcement learning terms. The Q-values that we have been discussing so far correspond to how good it is to take a certain action given a certain state. This can be written as Q(s,a). This action given state can actually be decomposed into two more fundamental notions of value. The first is the value function V(s), which says simple how good it is to be in any given state. The second is the advantage function A(a), which tells how much better taking a certain action would be compared to the others. We can then think of Q as being the combination of V and A. More formally:\n",
    "\n",
    "        Q(s,a) =V(s) + A(a)\n",
    "        \n",
    "The goal of Dueling DQN is to have a network that separately computes the advantage and value functions, and combines them back into a single Q-function only at the final layer. It may seem somewhat pointless to do this at first glance. Why decompose a function that we will just put back together? The key to realizing the benefit is to appreciate that our reinforcement learning agent may not need to care about both value and advantage at any given time. For example: imagine sitting outside in a park watching the sunset. It is beautiful, and highly rewarding to be sitting there. No action needs to be taken, and it doesn’t really make sense to think of the value of sitting there as being conditioned on anything beyond the environmental state you are in. We can achieve more robust estimates of state value by decoupling it from the necessity of being attached to specific actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "![Env](https://cdn-images-1.medium.com/max/800/1*R2nBdO9nJJVY_z0MQO5UsQ.png)\n",
    "\n",
    "Now that we have learned all the tricks to get the most out of our DQN, let’s actually try it on a game environment! While the DQN we have described above could learn ATARI games with enough training, getting the network to perform well on those games takes at least a day of training on a powerful machine. For educational purposes, I have built a simple game environment which our DQN learns to master in a couple hours on a moderately powerful machine (I am using a GTX970). In the environment the agent controls a blue square, and the goal is to navigate to the green squares (reward +1) while avoiding the red squares (reward -1). At the start of each episode all squares are randomly placed within a 5x5 grid-world. The agent has 50 steps to achieve as large a reward as possible. Because they are randomly positioned, the agent needs to do more than simply learn a fixed path, as was the case in the FrozenLake environment from Tutorial 0. Instead the agent must learn a notion of spatial relationships between the blocks. And indeed, it is able to do just that!\n",
    "\n",
    "The game environment outputs 84x84x3 color images, and uses function calls as similar to the OpenAI gym as possible. In doing so, it should be easy to modify this code to work on any of the OpenAI atari games. I encourage those with the time and computing resources necessary to try getting the agent to perform well in an ATARI game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Actor-Critic Agents (A3C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will provide a tutorial on implementing the Asynchronous Advantage Actor-Critic (A3C) algorithm in Tensorflow. We will use it to solve a simple challenge in a 3D Doom environment! With the holidays right around the corner, this will be my final post for the year, and I hope it will serve as a culmination of all the previous topics in the series. If you haven’t yet, or are new to Deep Learning and Reinforcement Learning, I suggest checking out the earlier entries in the series before going through this post in order to understand all the building blocks which will be utilized here. If you have been following the series: thank you! I have learned so much about RL in the past year, and am happy to have shared it with everyone through this article series.\n",
    "\n",
    "So what is A3C? The [A3C algorithm](https://arxiv.org/pdf/1602.01783.pdf) was released by Google’s DeepMind group earlier this year, and it made a splash by… essentially obsoleting DQN. It was faster, simpler, more robust, and able to achieve much better scores on the standard battery of Deep RL tasks. On top of all that it could work in continuous as well as discrete action spaces. Given this, it has become the go-to Deep RL algorithm for new challenging problems with complex state and action spaces. In fact, OpenAI just released a version of A3C as their “universal starter agent” for working with their new (and very diverse) set of Universe environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 3 As of A3C\n",
    "\n",
    "![Diagram of A3C high-level arcchitecture](https://cdn-images-1.medium.com/max/800/1*YtnGhtSAMnnHSL8PvS7t_w.png)\n",
    "\n",
    "Asynchronous Advantage Actor-Critic is quite a mouthful. Let’s start by unpacking the name, and from there, begin to unpack the mechanics of the algorithm itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Asynchronous**: Unlike DQN, where a single agent represented by a single neural network interacts with a single environment, A3C utilizes multiple incarnations of the above in order to learn more efficiently. In A3C there is a global network, and multiple worker agents which each have their own set of network parameters. Each of these agents interacts with it’s own copy of the environment at the same time as the other agents are interacting with their environments. The reason this works better than having a single agent (beyond the speedup of getting more work done), is that the experience of each agent is independent of the experience of the others. In this way the overall experience available for training becomes more diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actor-Critic**: So far this series has focused on value-iteration methods such as Q-learning, or policy-iteration methods such as Policy Gradient. Actor-Critic combines the benefits of both approaches. In the case of A3C, our network will estimate both a value function V(s) (how good a certain state is to be in) and a policy π(s) (a set of action probability outputs). These will each be separate fully-connected layers sitting at the top of the network. Critically, the agent uses the value estimate (the critic) to update the policy (the actor) more intelligently than traditional policy gradient methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantage**: If we think back to our implementation of Policy Gradient, the update rule used the discounted returns from a set of experiences in order to tell the agent which of its actions were “good” and which were “bad.” The network was then updated in order to encourage and discourage actions appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Discounted Reward: R = γ(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insight of using advantage estimates rather than just discounted returns is to allow the agent to determine not just how good its actions were, but how much better they turned out to be than expected. Intuitively, this allows the algorithm to focus on where the network’s predictions were lacking. If you recall from the Dueling Q-Network architecture, the advantage function is as follow:\n",
    "\n",
    "                    Advantage: A = Q(s,a) - V(s)\n",
    "\n",
    "Since we won’t be determining the Q values directly in A3C, we can use the discounted returns (R) as an estimate of Q(s,a) to allow us to generate an estimate of the advantage.\n",
    "\n",
    "                    Advantage Estimate: A = R - V(s)\n",
    "\n",
    "In this tutorial, we will go even further, and utilize a slightly different version of advantage estimation with lower variance referred to as Generalized Advantage Estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Algorithm\n",
    "![workflow](https://cdn-images-1.medium.com/max/800/1*Hzql_1t0-wwDxiz0C97AcQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the process of building this implementation of the A3C algorithm, I used as reference the quality implementations by [DennyBritz](https://github.com/dennybritz/reinforcement-learning) and [OpenAI](https://github.com/openai/universe-starter-agent). \n",
    "\n",
    "Both of which I highly recommend if you’d like to see alternatives to my code here. Each section embedded here is taken out of context for instructional purposes, and won’t run on its own. To view and run the full, functional A3C implementation, see this [Github repository](https://github.com/awjuliani/DeepRL-Agents/blob/master/A3C-Doom.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general outline of the code architecture is:\n",
    "\n",
    "- **AC_Network** — This class contains all the Tensorflow ops to create the networks themselves.\n",
    "- **Worker** — This class contains a copy of AC_Network, an environment class, as well as all the logic for interacting with the environment, and updating the global network.\n",
    "- High-level code for establishing the Worker instances and running them in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The A3C algorithm begins by constructing the global network. This network will consist of convolutional layers to process spatial dependencies, followed by an LSTM layer to process temporal dependencies, and finally, value and policy output layers. Below is example code for establishing the network graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AC_Network():\n",
    "    def __init__(self,s_size,a_size,scope,trainer):\n",
    "        with tf.variable_scope(scope):\n",
    "            #Input and visual encoding layers\n",
    "            self.inputs = tf.placeholder(shape=[None,s_size],dtype=tf.float32)\n",
    "            self.imageIn = tf.reshape(self.inputs,shape=[-1,84,84,1])\n",
    "            self.conv1 = slim.conv2d(activation_fn=tf.nn.elu,\n",
    "                inputs=self.imageIn,num_outputs=16,\n",
    "                kernel_size=[8,8],stride=[4,4],padding='VALID')\n",
    "            self.conv2 = slim.conv2d(activation_fn=tf.nn.elu,\n",
    "                inputs=self.conv1,num_outputs=32,\n",
    "                kernel_size=[4,4],stride=[2,2],padding='VALID')\n",
    "            hidden = slim.fully_connected(slim.flatten(self.conv2),256,activation_fn=tf.nn.elu)\n",
    "            \n",
    "            #Recurrent network for temporal dependencies\n",
    "            lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(256,state_is_tuple=True)\n",
    "            c_init = np.zeros((1, lstm_cell.state_size.c), np.float32)\n",
    "            h_init = np.zeros((1, lstm_cell.state_size.h), np.float32)\n",
    "            self.state_init = [c_init, h_init]\n",
    "            c_in = tf.placeholder(tf.float32, [1, lstm_cell.state_size.c])\n",
    "            h_in = tf.placeholder(tf.float32, [1, lstm_cell.state_size.h])\n",
    "            self.state_in = (c_in, h_in)\n",
    "            rnn_in = tf.expand_dims(hidden, [0])\n",
    "            step_size = tf.shape(self.imageIn)[:1]\n",
    "            state_in = tf.nn.rnn_cell.LSTMStateTuple(c_in, h_in)\n",
    "            lstm_outputs, lstm_state = tf.nn.dynamic_rnn(\n",
    "                lstm_cell, rnn_in, initial_state=state_in, sequence_length=step_size,\n",
    "                time_major=False)\n",
    "            lstm_c, lstm_h = lstm_state\n",
    "            self.state_out = (lstm_c[:1, :], lstm_h[:1, :])\n",
    "            rnn_out = tf.reshape(lstm_outputs, [-1, 256])\n",
    "            \n",
    "            #Output layers for policy and value estimations\n",
    "            self.policy = slim.fully_connected(rnn_out,a_size,\n",
    "                activation_fn=tf.nn.softmax,\n",
    "                weights_initializer=normalized_columns_initializer(0.01),\n",
    "                biases_initializer=None)\n",
    "            self.value = slim.fully_connected(rnn_out,1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=normalized_columns_initializer(1.0),\n",
    "                biases_initializer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a set of worker agents, each with their own network and environment are created. Each of these workers are run on a separate processor thread, so there should be no more workers than there are threads on your CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"): \n",
    "    master_network = AC_Network(s_size,a_size,'global',None) # Generate global network\n",
    "    num_workers = multiprocessing.cpu_count() # Set workers ot number of available CPU threads\n",
    "    workers = []\n",
    "    # Create worker classes\n",
    "    for i in range(num_workers):\n",
    "        workers.append(Worker(DoomGame(),i,s_size,a_size,trainer,saver,model_path))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    if load_model == True:\n",
    "        print 'Loading Model...'\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    # This is where the asynchronous magic happens.\n",
    "    # Start the \"work\" process for each worker in a separate threat.\n",
    "    worker_threads = []\n",
    "    for worker in workers:\n",
    "        worker_work = lambda: worker.work(max_episode_length,gamma,master_network,sess,coord)\n",
    "        t = threading.Thread(target=(worker_work))\n",
    "        t.start()\n",
    "        worker_threads.append(t)\n",
    "    coord.join(worker_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ From here we go asynchronous ~\n",
    "\n",
    "Each worker begins by setting its network parameters to those of the global network. We can do this by constructing a Tensorflow op which sets each variable in the local worker network to the equivalent variable value in the global network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copies one set of variables to another.\n",
    "# Used to set worker network parameters to those of global network.\n",
    "def update_target_graph(from_scope,to_scope):\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, from_scope)\n",
    "    to_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, to_scope)\n",
    "\n",
    "    op_holder = []\n",
    "    for from_var,to_var in zip(from_vars,to_vars):\n",
    "        op_holder.append(to_var.assign(from_var))\n",
    "    return op_holder\n",
    "\n",
    "class Worker():\n",
    "    def __init__(self,game,name,s_size,a_size,trainer,saver,model_path):\n",
    "        ....\n",
    "        ....\n",
    "        ....\n",
    "        #Create the local copy of the network and the tensorflow op to copy global paramters to local network\n",
    "        self.local_AC = AC_Network(s_size,a_size,self.name,trainer)\n",
    "        self.update_local_ops = update_target_graph('global',self.name)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each worker then interacts with its own copy of the environment and collects experience. Each keeps a list of experience tuples (observation, action, reward, done, value) that is constantly added to from interactions with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "      ....\n",
    "      ....\n",
    "      ....\n",
    "      def work(self,max_episode_length,gamma,global_AC,sess,coord):\n",
    "        episode_count = 0\n",
    "        total_step_count = 0\n",
    "        print \"Starting worker \" + str(self.number)\n",
    "        with sess.as_default(), sess.graph.as_default():                 \n",
    "            while not coord.should_stop():\n",
    "                sess.run(self.update_local_ops)\n",
    "                episode_buffer = []\n",
    "                episode_values = []\n",
    "                episode_frames = []\n",
    "                episode_reward = 0\n",
    "                episode_step_count = 0\n",
    "                d = False\n",
    "                \n",
    "                self.env.new_episode()\n",
    "                s = self.env.get_state().screen_buffer\n",
    "                episode_frames.append(s)\n",
    "                s = process_frame(s)\n",
    "                rnn_state = self.local_AC.state_init\n",
    "                \n",
    "                while self.env.is_episode_finished() == False:\n",
    "                    #Take an action using probabilities from policy network output.\n",
    "                    a_dist,v,rnn_state = sess.run([self.local_AC.policy,self.local_AC.value,self.local_AC.state_out], \n",
    "                        feed_dict={self.local_AC.inputs:[s],\n",
    "                        self.local_AC.state_in[0]:rnn_state[0],\n",
    "                        self.local_AC.state_in[1]:rnn_state[1]})\n",
    "                    a = np.random.choice(a_dist[0],p=a_dist[0])\n",
    "                    a = np.argmax(a_dist == a)\n",
    "\n",
    "                    r = self.env.make_action(self.actions[a]) / 100.0\n",
    "                    d = self.env.is_episode_finished()\n",
    "                    if d == False:\n",
    "                        s1 = self.env.get_state().screen_buffer\n",
    "                        episode_frames.append(s1)\n",
    "                        s1 = process_frame(s1)\n",
    "                    else:\n",
    "                        s1 = s\n",
    "                        \n",
    "                    episode_buffer.append([s,a,r,s1,d,v[0,0]])\n",
    "                    episode_values.append(v[0,0])\n",
    "\n",
    "                    episode_reward += r\n",
    "                    s = s1                    \n",
    "                    total_steps += 1\n",
    "                    episode_step_count += 1\n",
    "                    \n",
    "                    #Specific to VizDoom. We sleep the game for a specific time.\n",
    "                    if self.sleep_time>0:\n",
    "                        sleep(self.sleep_time)\n",
    "                    \n",
    "                    # If the episode hasn't ended, but the experience buffer is full, then we\n",
    "                    # make an update step using that experience rollout.\n",
    "                    if len(episode_buffer) == 30 and d != True and episode_step_count != max_episode_length - 1:\n",
    "                        # Since we don't know what the true final return is, we \"bootstrap\" from our current\n",
    "                        # value estimation.\n",
    "                        v1 = sess.run(self.local_AC.value, \n",
    "                            feed_dict={self.local_AC.inputs:[s],\n",
    "                            self.local_AC.state_in[0]:rnn_state[0],\n",
    "                            self.local_AC.state_in[1]:rnn_state[1]})[0,0]\n",
    "                        v_l,p_l,e_l,g_n,v_n = self.train(global_AC,episode_buffer,sess,gamma,v1)\n",
    "                        episode_buffer = []\n",
    "                        sess.run(self.update_local_ops)\n",
    "                    if d == True:\n",
    "                        break\n",
    "                                            \n",
    "                self.episode_rewards.append(episode_reward)\n",
    "                self.episode_lengths.append(episode_step_count)\n",
    "                self.episode_mean_values.append(np.mean(episode_values))\n",
    "                \n",
    "                # Update the network using the experience buffer at the end of the episode.\n",
    "                v_l,p_l,e_l,g_n,v_n = self.train(global_AC,episode_buffer,sess,gamma,0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the worker’s experience history is large enough, we use it to determine discounted return and advantage, and use those to calculate value and policy losses. We also calculate an entropy (H) of the policy. This corresponds to the spread of action probabilities. If the policy outputs actions with relatively similar probabilities, then entropy will be high, but if the policy suggests a single action with a large probability then entropy will be low. We use the entropy as a means of improving exploration, by encouraging the model to be conservative regarding its sureness of the correct action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        Value Loss: L = Σ(R - V(s))²\n",
    "                                        Policy Loss: L = -log(π(s)) * A(s) - β*H(π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A worker then uses these losses to obtain gradients with respect to its network parameters. Each of these gradients are typically clipped in order to prevent overly-large parameter updates which can destabilize the policy.\n",
    "\n",
    "A worker then uses the gradients to update the global network parameters. In this way, the global network is constantly being updated by each of the agents, as they interact with their environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AC_Network():\n",
    "    def __init__(self,s_size,a_size,scope,trainer):\n",
    "        ....\n",
    "        ....\n",
    "        ....\n",
    "        if scope != 'global':\n",
    "            self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "            self.actions_onehot = tf.one_hot(self.actions,a_size,dtype=tf.float32)\n",
    "            self.target_v = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "            self.advantages = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "\n",
    "            self.responsible_outputs = tf.reduce_sum(self.policy * self.actions_onehot, [1])\n",
    "\n",
    "            #Loss functions\n",
    "            self.value_loss = 0.5 * tf.reduce_sum(tf.square(self.target_v - tf.reshape(self.value,[-1])))\n",
    "            self.entropy = - tf.reduce_sum(self.policy * tf.log(self.policy))\n",
    "            self.policy_loss = -tf.reduce_sum(tf.log(self.responsible_outputs)*self.advantages)\n",
    "            self.loss = 0.5 * self.value_loss + self.policy_loss - self.entropy * 0.01\n",
    "\n",
    "            #Get gradients from local network using local losses\n",
    "            local_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)\n",
    "            self.gradients = tf.gradients(self.loss,local_vars)\n",
    "            self.var_norms = tf.global_norm(local_vars)\n",
    "            grads,self.grad_norms = tf.clip_by_global_norm(self.gradients,40.0)\n",
    "\n",
    "            #Apply local gradients to global network\n",
    "            global_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'global')\n",
    "            self.apply_grads = trainer.apply_gradients(zip(grads,global_vars))\n",
    "\n",
    "class Worker():\n",
    "      ....\n",
    "      ....\n",
    "      ....\n",
    "      def train(self,global_AC,rollout,sess,gamma,bootstrap_value):\n",
    "        rollout = np.array(rollout)\n",
    "        observations = rollout[:,0]\n",
    "        actions = rollout[:,1]\n",
    "        rewards = rollout[:,2]\n",
    "        next_observations = rollout[:,3]\n",
    "        values = rollout[:,5]\n",
    "\n",
    "        # Here we take the rewards and values from the rollout, and use them to \n",
    "        # generate the advantage and discounted returns. \n",
    "        # The advantage function uses \"Generalized Advantage Estimation\"\n",
    "        self.rewards_plus = np.asarray(rewards.tolist() + [bootstrap_value])\n",
    "        discounted_rewards = discount(self.rewards_plus,gamma)[:-1]\n",
    "        self.value_plus = np.asarray(values.tolist() + [bootstrap_value])\n",
    "        advantages = rewards + gamma * self.value_plus[1:] - self.value_plus[:-1]\n",
    "        advantages = discount(advantages,gamma)\n",
    "\n",
    "        # Update the global network using gradients from loss\n",
    "        # Generate network statistics to periodically save\n",
    "        rnn_state = self.local_AC.state_init\n",
    "        feed_dict = {self.local_AC.target_v:discounted_rewards,\n",
    "            self.local_AC.inputs:np.vstack(observations),\n",
    "            self.local_AC.actions:actions,\n",
    "            self.local_AC.advantages:advantages,\n",
    "            self.local_AC.state_in[0]:rnn_state[0],\n",
    "            self.local_AC.state_in[1]:rnn_state[1]}\n",
    "        v_l,p_l,e_l,g_n,v_n,_ = sess.run([self.local_AC.value_loss,\n",
    "            self.local_AC.policy_loss,\n",
    "            self.local_AC.entropy,\n",
    "            self.local_AC.grad_norms,\n",
    "            self.local_AC.var_norms,\n",
    "            self.local_AC.apply_grads],\n",
    "            feed_dict=feed_dict)\n",
    "        return v_l / len(rollout),p_l / len(rollout),e_l / len(rollout), g_n,v_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a successful update is made to the global network, the whole process repeats! The worker then resets its own network parameters to those of the global network, and the process begins again.\n",
    "\n",
    "To view the full and functional code, see the Github repository [here](https://github.com/awjuliani/DeepRL-Agents/blob/master/A3C-Doom.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Doom\n",
    "\n",
    "![Doom](https://cdn-images-1.medium.com/max/800/1*yjPVxRywI8U9SKfCMCKR1A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The robustness of A3C allows us to tackle a new generation of reinforcement learning challenges, one of which is 3D environments! We have come a long way from multi-armed bandits and grid-worlds, and in this tutorial, I have set up the code to allow for playing through the first VizDoom challenge. \n",
    "\n",
    "VizDoom is a system to allow for RL research using the classic Doom game engine. The maintainers of VizDoom recently created a pip package, so installing it is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install vizdoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is installed, we will be using the basic.wad environment, which is provided in the Github repository, and needs to be placed in the working directory.\n",
    "\n",
    "The challenge consists of controlling an avatar from a first person perspective in a single square room. There is a single enemy on the opposite side of the room, which appears in a random location each episode. The agent can only move to the left or right, and fire a gun. The goal is to shoot the enemy as quickly as possible using as few bullets as possible. The agent has 300 time steps per episode to shoot the enemy. Shooting the enemy yields a reward of 1, and each time step as well as each shot yields a small penalty. After about 500 episodes per worker agent, the network learns a policy to quickly solve the challenge. Feel free to adjust parameters such as learning rate, clipping magnitude, update frequency, etc. to attempt to achieve ever greater performance or utilize A3C in your own RL tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Average reward over time for three workers on Doom task. 0.5 reward corresponds to optimal performance. X-axis represents number of training episodes per worker.](https://cdn-images-1.medium.com/max/800/1*DVaQXq6aVWYsU3S3INkV_w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MarioKart\n",
    "\n",
    "The goal of this part is to apply Reinforcement Learning on Mario Kart. The first step deals with single player while the second focuses on using two models for two players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Player\n",
    "\n",
    "#### Running the MarioKart Environement in OpenAI Gym\n",
    "In this section, we will start configuring the OpenAI Gym environement for MarioKart.\n",
    "The MarioKart enviroenment is not an official OpenAI Gym, it is an open source community project that can be found at https://github.com/bzier/gym-mupen64plus\n",
    "\n",
    "![goal](https://cdn-images-1.medium.com/max/800/1*rb8r_CrUM8otagIb4ck_Tw.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym, gym_mupen64plus\n",
    "\n",
    "env = gym.make('Mario-Kart-Luigi-Raceway-v0')\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "for i in range(88):\n",
    "    (obs, rew, end, info) = env.step([0, 0, 0, 0, 0]) # NOOP until green light\n",
    "    env.render()\n",
    "\n",
    "for i in range(100):\n",
    "    (obs, rew, end, info) = env.step([0, 0, 1, 0, 0]) # Drive straight\n",
    "    env.render()\n",
    "\n",
    "raw_input(\"Press <enter> to exit... \")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you could launch a dummy mariokart for a single player, the idea would be to use A3C to initiate the learning process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Training\n",
    "\n",
    "In the following examples, I use `mario-kart-agent` as the name of my project. You can use your own name instead, or you can remove the switch (`-p`) and project name and they will default to using the directory name.\n",
    "\n",
    "## Start training:\n",
    "After you've completed the build instructions above, starting training is as simple as:\n",
    "```sh\n",
    "docker-compose -p mario-kart-agent up -d\n",
    "```\n",
    "\n",
    "## Scaling workers:\n",
    "If you have sufficient CPU, you can also spin up multiple worker containers that all communicate with the same parameter server container:\n",
    "```sh\n",
    "docker-compose -p mario-kart-agent up -d --scale worker=2\n",
    "```\n",
    "From the original A3C starter agent `README` page, the following recommendation was made. My CPU isn't good enough to even run more than one at a time, so I can't verify if this holds true for Mario Kart as well or not:\n",
    ">For best performance, it is recommended for the number of workers to not exceed available number of CPU cores.\n",
    "\n",
    "## Stop training:\n",
    "When you are done, you can tear down the containers with:\n",
    "```sh\n",
    "docker-compose -p mario-kart-agent down\n",
    "```\n",
    "\n",
    "**`Note 1`**: This will destroy all of the containers, but not the underlying images that you previously built. You can just follow the instructions in [this section](#start-training) to start again.\n",
    "\n",
    "**`Note 2`**: This will ***not*** destroy the `mklogs` volume, which is where all of the log data and model checkpoints are stored. This means that starting the containers again will pick up training essentially where it left off (not mid-episode, but with the parameters of the neural network where they were).\n",
    "\n",
    "## Monitoring training:\n",
    "### Tensorboard (i.e. training data)\n",
    "Tensorboard is started in the parameter server container. This container has the Tensorboard port (`12345`) mapped to the same port on your host. In other words, you can browse to [`http://localhost:12345`](http://localhost:12345) to view the Tensorboard UI.\n",
    "\n",
    "### VNC (i.e. watch the agent)\n",
    "VNC is started in each worker container. Because workers can be scaled out, we can't map the container port to the host machine. Otherwise each of the containers would conflict fighting for the same host port. Instead, you can examine each worker container with:\n",
    "```sh\n",
    "docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}::{{range $p, $conf := .NetworkSettings.Ports}}{{$p}} -> localhost::{{(index $conf 0).HostPort}}{{end}}' $INSTANCE_ID\n",
    "```\n",
    "*Here `$INSTANCE_ID` is the name or ID of the worker container you're interested in*\n",
    "\n",
    "This will return something like:\n",
    "```sh\n",
    "172.17.0.2::5900/tcp -> localhost::32790\n",
    "```\n",
    "Then you can use your favorite VNC client to connect to localhost on the dynamically chosen port and watch the agent in real-time. Note that running the VNC client can cause some performance overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi player\n",
    "Go through the code and update it so that it can now launch the game in multiplayer mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
